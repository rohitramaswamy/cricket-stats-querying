{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohitramaswamy/Desktop/programming-stuff/sports-data-scraping/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "               Player  2006\n",
      "0     Rasheed Wallace     0\n",
      "1    Richard Hamilton     0\n",
      "2     Stephen Jackson     0\n",
      "3         Kobe Bryant     0\n",
      "4         Baron Davis     0\n",
      "5         Mikki Moore     0\n",
      "6   Amar'e Stoudemire     0\n",
      "7       Kevin Garnett     0\n",
      "8      Gerald Wallace     0\n",
      "9     Carmelo Anthony     0\n",
      "10      Allen Iverson     0\n",
      "11      Dirk Nowitzki     0\n",
      "12    Jermaine O'Neal     0\n",
      "13         Lamar Odom     0\n",
      "14        Ricky Davis     0\n",
      "15    Antonio McDyess     0\n",
      "16          Raja Bell     0\n",
      "17         Tim Duncan     0\n",
      "18         Eddy Curry     0\n",
      "19      Desmond Mason     0\n",
      "20     Tyson Chandler     0\n",
      "21       Kirk Hinrich     0\n",
      "22   Chauncey Billups     0\n",
      "23     Jamaal Tinsley     0\n",
      "24      Zach Randolph     0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "year = 2006\n",
    "df = pd.DataFrame() \n",
    "url = 'https://www.teamrankings.com/nba/player-stat/fouls-technical?rate=season-totals&season_id=204'\n",
    "try:\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()  # Check if the request was successful\n",
    "\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find all tables in the page\n",
    "    tables = soup.find_all('table')\n",
    "\n",
    "    # Convert the first table to a pandas DataFrame\n",
    "    if tables:\n",
    "        print(len(tables))\n",
    "        df = pd.DataFrame(pd.read_html(StringIO(str(tables[0])))[0])[[\"Player\"]].head(25)\n",
    " \n",
    "\n",
    "\n",
    "        df[f'{year}'] = 0\n",
    "        # df = df[['Player', 'Goals']]\n",
    "        \n",
    "        print(df)\n",
    "        # if 'Player' in df.columns and 'Runs' in df.columns:\n",
    "        #     df = df[['Player', 'Wkts']].head(15)\n",
    "        #     # df.rename(columns={'Wkts': f'{year}'}, inplace=True)\n",
    "        #     # current_df = pd.merge(current_df, df, on='Player', how='outer')\n",
    "\n",
    "        # else:\n",
    "        #     print(f\"'Player' or 'Runs' column not found for the year {year}\")\n",
    "    else:\n",
    "        print(\"No tables found on the page.\")\n",
    "except requests.HTTPError as e:\n",
    "    print(f\"HTTP error occurred: {e.response.status_code} - {e.response.reason}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()  \u001b[38;5;66;03m# Check if the request was successful\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Parse the HTML content\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m soup \u001b[38;5;241m=\u001b[39m \u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhtml.parser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Find all tables in the page\u001b[39;00m\n\u001b[1;32m     18\u001b[0m tables \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/programming-stuff/sports-data-scraping/.venv/lib/python3.9/site-packages/bs4/__init__.py:335\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39minitialize_soup(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 335\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m     success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/programming-stuff/sports-data-scraping/.venv/lib/python3.9/site-packages/bs4/__init__.py:478\u001b[0m, in \u001b[0;36mBeautifulSoup._feed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;66;03m# Convert the document to Unicode.\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 478\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;66;03m# Close out any unfinished strings and close all the open tags.\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendData()\n",
      "File \u001b[0;32m~/Desktop/programming-stuff/sports-data-scraping/.venv/lib/python3.9/site-packages/bs4/builder/_htmlparser.py:380\u001b[0m, in \u001b[0;36mHTMLParserTreeBuilder.feed\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m    378\u001b[0m parser\u001b[38;5;241m.\u001b[39msoup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoup\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 380\u001b[0m     \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m     parser\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;66;03m# html.parser raises AssertionError in rare cases to\u001b[39;00m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# indicate a fatal problem with the markup, especially\u001b[39;00m\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;66;03m# when there's an error in the doctype declaration.\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/html/parser.py:110\u001b[0m, in \u001b[0;36mHTMLParser.feed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Feed data to the parser.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03mCall this as often as you want, with as little or as much text\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03mas you want (may include '\\n').\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrawdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrawdata \u001b[38;5;241m+\u001b[39m data\n\u001b[0;32m--> 110\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgoahead\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/html/parser.py:170\u001b[0m, in \u001b[0;36mHTMLParser.goahead\u001b[0;34m(self, end)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m startswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m'\u001b[39m, i):\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m starttagopen\u001b[38;5;241m.\u001b[39mmatch(rawdata, i): \u001b[38;5;66;03m# < + letter\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m         k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_starttag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m startswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</\u001b[39m\u001b[38;5;124m\"\u001b[39m, i):\n\u001b[1;32m    172\u001b[0m         k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_endtag(i)\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/html/parser.py:322\u001b[0m, in \u001b[0;36mHTMLParser.parse_starttag\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rest:\n\u001b[1;32m    320\u001b[0m     attrvalue \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m attrvalue[:\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m==\u001b[39m attrvalue[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;129;01mor\u001b[39;00m \\\n\u001b[0;32m--> 322\u001b[0m      attrvalue[:\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m==\u001b[39m attrvalue[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m    323\u001b[0m     attrvalue \u001b[38;5;241m=\u001b[39m attrvalue[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attrvalue:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize current_df correctly\n",
    "current_df = pd.DataFrame()\n",
    "# Function to remove text within parentheses\n",
    "end_year = 2025\n",
    "current_year = year + 1\n",
    "\n",
    "for i in range(end_year - current_year):\n",
    "\n",
    "    url = f'https://www.teamrankings.com/nba/player-stat/fouls-technical?rate=season-totals&season_id={204 + (current_year - 2007)}'\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()  # Check if the request was successful\n",
    "\n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Find all tables in the page\n",
    "        tables = soup.find_all('table')\n",
    "\n",
    "        # Convert the first table to a pandas DataFrame\n",
    "        if tables:\n",
    "                   \n",
    "\n",
    "            current_df = pd.DataFrame(pd.read_html(StringIO(str(tables[0])))[0])[[\"Player\", \"Value\"]].head(25)\n",
    "            current_df.rename(columns={'Value': f'{current_year}'}, inplace=True)\n",
    "\n",
    "           \n",
    "        else:\n",
    "            print(\"No tables found on the page.\")\n",
    "    except requests.HTTPError as e:\n",
    "        print(f\"HTTP error occurred: {e.response.status_code} - {e.response.reason}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "    \n",
    "    df = pd.merge(df, current_df, on='Player', how='outer')\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "\n",
    "\n",
    "     # Add the goals\n",
    "    df[f'{current_year}'] = df[f'{current_year - 1}'] + df[f'{current_year}'] \n",
    "    \n",
    "\n",
    "    current_year = current_year + 1\n",
    "\n",
    "   \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_non_letters(name):\n",
    "    # Create an empty list to store only the letters\n",
    "    filtered_name = [char for char in name if char.isalpha()]\n",
    "    # Join the list into a string\n",
    "    stripped_name = ''.join(filtered_name)\n",
    "\n",
    "\n",
    "    return stripped_name\n",
    "\n",
    "def get_image(name):\n",
    "    name_list = list(name.split(\" \"))\n",
    "    name_list = [strip_non_letters(name) for name in name_list]\n",
    "    last_name = \"\"\n",
    "    if(len(name_list[1]) < 5):\n",
    "        last_name = name_list[1]\n",
    "    else:\n",
    "        last_name = name_list[1][:5]\n",
    "    \n",
    "    # Using indexing sequence\n",
    "    first_name = name_list[0][:2]\n",
    "    format = (last_name + first_name + \"01\").lower()\n",
    "    return(f\"https://www.basketball-reference.com/req/202106291/images/headshots/{format}.jpg\")\n",
    "\n",
    "\n",
    "df[\"Image\"] = df[\"Player\"].apply(get_image)\n",
    "\n",
    "excel_file = \"tech_fouls.xlsx\" \n",
    " \n",
    "# Write DataFrame to Excel \n",
    "df.to_excel(excel_file, index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 of 3: Failed to connect to the server. Retrying in 5 seconds...\n",
      "Attempt 2 of 3: Failed to connect to the server. Retrying in 5 seconds...\n",
      "Attempt 3 of 3: Failed to connect to the server. Retrying in 5 seconds...\n",
      "Failed to fetch data after multiple attempts.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.exceptions import ConnectionError, Timeout, TooManyRedirects, RequestException\n",
    "import time\n",
    "\n",
    "url = \"https://www.teamrankings.com/nba/player-stat/fouls-technical?rate=season-totals&season_id=204\"\n",
    "\n",
    "def fetch_data(url, retries=3, delay=5):\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            return response.text\n",
    "        except ConnectionError:\n",
    "            print(f\"Attempt {i+1} of {retries}: Failed to connect to the server. Retrying in {delay} seconds...\")\n",
    "            time.sleep(delay)\n",
    "        except Timeout:\n",
    "            print(f\"Attempt {i+1} of {retries}: The request timed out. Retrying in {delay} seconds...\")\n",
    "            time.sleep(delay)\n",
    "        except TooManyRedirects:\n",
    "            print(\"Too many redirects. The URL might be incorrect.\")\n",
    "            break\n",
    "        except RequestException as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            break\n",
    "    return None\n",
    "\n",
    "data = fetch_data(url)\n",
    "if data:\n",
    "    # Process the data here\n",
    "    print(\"Data fetched successfully!\")\n",
    "else:\n",
    "    print(\"Failed to fetch data after multiple attempts.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
